<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="shortcut icon" href="assets/favicon.ico/">
    <link rel="apple-touch-icon" sizes="57x57" href="../assets/favicon.ico/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="../assets/favicon.ico/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="../assets/favicon.ico/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="../assets/favicon.ico/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="../assets/favicon.ico/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="../assets/favicon.ico/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="../assets/favicon.ico/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="../assets/favicon.ico/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="../assets/favicon.ico/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192"  href="../assets/favicon.ico/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../assets/favicon.ico/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="../assets/favicon.ico/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../assets/favicon.ico/favicon-16x16.png">
    <link rel="manifest" href="../assets/favicon.ico/manifest.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="../assets/favicon.ico/ms-icon-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <link href="https://unpkg.com/aos@2.3.1/dist/aos.css" rel="stylesheet">
    <script src="https://unpkg.com/aos@2.3.1/dist/aos.js"></script>
    <link rel="stylesheet" href="../css/style_main.css">
    <link rel="stylesheet" href="../css/style_casestudy.css">
    <title>Hanbyeol Lee | Portfolio</title>
</head>
<body>
    <script>AOS.init();</script>
    <header>
        <div class="nav-bar">
            <a href="../" class="logo font-sans-serif-en"><b>Hanbyeol</b></a>
            <ul>
                <li><a href="/" class="current font-sans-serif-en">Work</a></li>
                <li><a href="../about" class="font-sans-serif-en">About</a></li>
            </ul>
        </div>
    </header>

    <main>
        <section class="project-intro-section">
            <img class="main-image" src="../assets/image/this-or-that/main.jpg">
            <div class="section-container">
                <h1 class="font-sans-serif-en">This or That</h1>
                <h3 class="font-sans-serif-kr">소셜 로봇의 포인팅 제스처와 발화 방식에 따른 사용자의 인식 연구</h2>
                <div class="project-info">
                    <div class="info-item">
                        <h3 class="font-sans-serif-en">Type</h3>
                        <p class="font-sans-serif-kr">Human-Robot Interaction 리서치</p>
                    </div>
                    <div class="info-item">
                        <h3 class="font-sans-serif-en">Affiliation</h3>
                        <p class="font-sans-serif-kr">KIST AIㆍ로봇연구소 지능로봇연구단</p>
                    </div>
                    <div class="info-item">
                        <h3 class="font-sans-serif-en">Role</h3>
                        <p class="font-sans-serif-kr">인터랙션 리서처/엔지니어</p>
                        <span class="font-sans-serif-kr">프로젝트 기획, 문헌 조사, 인터랙션 디자인, 제품 디자인, 프로토타입 개발, 사용자 조사, 데이터 분석, 논문 집필</span>
                    </div>
                    <div class="info-item">
                        <h3 class="font-sans-serif-en">Tools</h3>
                        <p class="font-sans-serif-kr">
                            SolidWorks <span class="font-sans-serif-kr">3D모델링</span>,
                            Raspberry Pi <span class="font-sans-serif-kr">하드웨어</span>,
                            TurtleBot <span class="font-sans-serif-kr">로봇플랫폼</span>,
                            SPSS <span class="font-sans-serif-kr">데이터분석</span>
                        </p>
                    </div>
                    <div class="info-item">
                        <h3 class="font-sans-serif-en">Achievement</h3>
                        <p class="font-sans-serif-kr"><a href="https://ieeexplore.ieee.org/document/9341067">IEEE/RSJ IROS 2020 학회 논문</a></p>
                    </div>
                    <div class="info-item">
                        <h3 class="font-sans-serif-en">Duration</h3>
                        <p class="font-sans-serif-kr">2019.12 ~ 2020.02 (3개월)</p>
                    </div>
                </div>
                <div class="project-detail">
                    <h2 class="font-sans-serif-en">Background</h2>
                    <p class="font-sans-serif-kr">
                        우리는 같은 공간에 있는 사람과 대화할 때 주변의 사물, 장소 등이 자주 토픽이 되고, 제스처나 지시어를 사용해 위치 정보를 공유한다.<br>
                        로봇 또한, 휴대폰이나 스마트 스피커와 달리 언어적 의사소통뿐만 아니라 비언어적 의사소통을 가능하게 하는 물리적인 형태(physical embodiment)를 가지고 있다.
                    </p>
                    <p class="font-sans-serif-kr">하지만, HRI 측면에서 로봇의 포인팅 연구는 몇 가지 제한이 있었다.</p>
                    <div class="quotation" data-aos="fade-up">
                        <h4 class="font-sans-serif-en">Design Question:</h4>
                        <p class="font-sans-serif-kr">“인간과 로봇이 효과적으로 상호작용할 수 있는 로봇의 포인팅 방식은 무엇일까?”</p>
                    </div>
                    <h3 class="font-sans-serif-en">Locative Deixis</h3>
                    <p class="font-sans-serif-kr">
                        직시어는 대화에서 자주 사용된다. 특히, 위치격 직시어(예시: 이거, 저거)는 주변에 있는 특정 대상을 청자 또는 독자가 이해할 수 있도록 언어를 사용해서 참조할 때 사용된다.<br>
                        하지만, 로봇은 언어적 의사소통에 있어 대부분 <b>서술적 직시어</b>(예시: 왼쪽에서 두 번째)를 사용한다.
                    </p>
                    <div class="img-wrapper" data-aos="fade-up">
                        <img src="../assets/image/this-or-that/background-01.png">
                        <p class="font-sans-serif-kr">직시어는 위치격 직시어와 서술적 직시어로 나뉠 수 있다.</p>
                    </div>
                    <h3 class="font-sans-serif-en">Pointing Gesture</h3>
                    <p class="font-sans-serif-kr">
                        포인팅 제스처는 유아가 첫 단어를 말하기 전 배우는 의사소통 기술 중 하나다<sup id="R01"><a href="#refer01" class="font-sans-serif-kr">1</a></sup>.
                        사람들은 복잡한 서술을 생략하기 위해 팔, 머리, 눈, 입술, 코와 같은 다양한 신체 부위를 사용하여 포인팅 제스처를 취한다<sup id="R02"><a href="#refer02" class="font-sans-serif-kr">2</a></sup>.
                        하지만, 대부분의 로봇 포인팅 제스처에 대한 연구는 <b>손가락</b>으로 가리키는 것으로 제한되었다.
                    </p>
                    <div class="img-wrapper" data-aos="fade-up">
                        <img src="../assets/image/this-or-that/background-02.png">
                        <p class="font-sans-serif-kr">사람은 다양한 신체 부위를 사용하여 포인팅 제스처를 취할 수 있다.</p>
                    </div>
                    <h3 class="font-sans-serif-en">Head Pointing</h3>
                    <p class="font-sans-serif-kr">
                        사람은 머리를 움직여서 특정 대상을 가리키기도 한다.
                        HRI 연구에 따르면 로봇이 머리를 움직여서 가리키는 것은 인간의 행동과 비슷한 효과를 나타낸다<sup id="R03"><a href="#refer03">3</a></sup>.
                        사람은 시선과 돌출된 코를 통해 포인팅 제스처를 취할 수 있는 반면에, 소셜 로봇의 머리는 대부분 <b>평면 디스플레이</b>를 사용하기 때문에 정확한 포인팅이 가능한지 알 수 없다.
                    </p>
                    <div class="img-wrapper" data-aos="fade-up">
                        <img src="../assets/image/this-or-that/background-03.png">
                        <p class="font-sans-serif-kr">사람은 시선과 돌출된 코를 통해 포인팅 제스처를 쉽게 취할 수 있다.</p>
                    </div>
                </div>
                <div class="project-detail">
                    <h2 class="font-sans-serif-en">Study Design</h2>
                    <div class="quotation" data-aos="fade-up">
                        <h4 class="font-sans-serif-en">Research Question:</h4>
                        <p class="font-sans-serif-kr">“로봇의 언어적, 비언어적 포인팅은 사용자의 인식에 어떤 영향을 끼치며, 효과적인 포인팅 인터랙션은 무엇일까?”</p>
                    </div>
                    <p class="font-sans-serif-kr">로봇의 포인팅 관련 발화 및 제스처를 다양한 조건으로 프로토타이핑한 후, 상황에 따라 로봇의 표현에 대한 사용자의 인식을 정량 조사한다.</p>
                    <h3 class="font-sans-serif-en">Independent Varialbes</h3>
                    <p class="font-sans-serif-kr">
                        로봇은 사용자에게 언어뿐만 아니라 포인팅 제스처를 통해 물체의 위치를 알릴 수 있다.
                        또한, 포인팅 제스처는 <b>시선(eye pointing)</b> 확장이다<sup id="R04"><a href="#refer04">4</a></sup>.<br>
                        즉, 시선은 포인팅 제스처의 기본이다.
                    </p>
                    <p class="font-sans-serif-kr">독립 변수는 언어 2가지, 포인팅 제스처 2가지, 시선 2가지로 설정하였다.</p>
                    <h4 class="font-sans-serif-kr">언어</h3>
                    <ul>
                        <li class="font-sans-serif-kr">지시적(deictic)</li>
                        <li class="font-sans-serif-kr">서술적(descriptive)</li>
                    </ul>
                    <h4 class="font-sans-serif-kr">포인팅 제스처</h3>
                    <ul>
                        <li class="font-sans-serif-kr">코가 있는(with nose)</li>
                        <li class="font-sans-serif-kr">코가 없는(without nose)</li>
                    </ul>
                    <h4 class="font-sans-serif-kr">시선</h3>
                    <ul>
                        <li class="font-sans-serif-kr">눈이 있는(with eyes)</li>
                        <li class="font-sans-serif-kr">눈이 없는(without eyes)</li>
                    </ul>
                    <div class="img-wrapper" data-aos="fade-up">
                        <img src="../assets/image/this-or-that/study-design-01.png">
                        <p class="font-sans-serif-kr">독립 변수: 언어(2가지) X 포인팅 제스처(2가지) X 시선(2가지)</p>
                    </div>
                    <h3 class="font-sans-serif-en">Prototyping</h3>
      			    <p class="font-sans-serif-kr"><b>Wizard of Oz</b> 기법 실험을 위한 로봇을 디자인하고 개발하였다.</p>
                    <h4 class="font-sans-serif-kr">사용한 소프트웨어</h4>
                    <ul>
                        <li class="font-sans-serif-kr">3D 모델링: SolidWorks</li>
                        <li class="font-sans-serif-kr">하드웨어: Raspberry Pi</li>
                        <li class="font-sans-serif-kr">로봇플랫폼: TurtleBot</li>
                    </ul>
                    <div class="img-wrapper" data-aos="fade-up">
                        <img src="../assets/image/this-or-that/study-design-02.png">
                        <p class="font-sans-serif-kr">제품 프로토타입</p>
                    </div>
                    <details>
                        <summary class="font-sans-serif-kr" style="cursor:pointer">제품 설계 세부 사항</summary>
                        <ul>
                            <li class="font-sans-serif-kr">로봇 프로토타입은 ROS 기반 모바일 로봇인 TurtleBot3를 기반으로 방향을 변경하면서 이동할 수 있다.</li>
                            <li class="font-sans-serif-kr">블루투스 통신으로 로봇의 언어 타입을 제어할 수 있다.</li>
                            <li class="font-sans-serif-kr">Raspberry Pi와 연결된 모니터를 통해 로봇의 시선을 제어할 수 있다.</li>
                            <li class="font-sans-serif-kr">로봇의 움직임은 블루투스 통신을 통해 조이스틱 컨트롤러를 통해 수동으로 제어된다.</li>
                        </ul>
                    </details>
                    <h3 class="font-sans-serif-en">Participants</h3>
                    <p class="font-sans-serif-kr">피험자를 모집하여 연구실 조사(in-lab study)로 실험이 진행되었다.</p>
                    <ul>
                        <li class="font-sans-serif-kr">피험자: 48명 (23세~37세 / 여성 26명, 남성 22명)</li>
                    </ul>
                    <details>
                        <summary class="font-sans-serif-kr" style="cursor:pointer">피험자 설계 세부 사항</summary>
                        <h4 class="font-sans-serif-kr">혼합 설계 (mixed design)</h4>
                        <ul>
                            <li class="font-sans-serif-kr">언어: within design - 피험자는 두 가지 언어를 모두 경험한다. (무작위 순서)</li>
                            <li class="font-sans-serif-kr">포인팅 제스처: within design - 피험자는 두 가지 포인팅 제스처를 모두 경험한다. (무작위 순서)</li>
                            <li class="font-sans-serif-kr">시선: between design - 피험자는 한 가지 시선을 경험한다.</li>
                        </ul>
                    </details>
                    <h3 class="font-sans-serif-en">Experiments</h3>
                    <p class="font-sans-serif-kr">로봇이 사용자와 상호작용하는 상황에 따라, 2가지의 실험을 진행하였다.</p>
                    <ul>
                        <li class="font-sans-serif-kr">명령형 포인팅 상황: 가리킨 객체에 대한 <b>요청</b> - 자리 안내(seat guide)</li>
                        <li class="font-sans-serif-kr">서술형 포인팅 상황: 가리킨 객체에 대한 <b>설명</b> - 전시 안내(exhibition guide)</li>
                    </ul>
                    <h3 class="font-sans-serif-en">Measurements</h3>
      			    <p class="font-sans-serif-kr">각 실험 조건에 대해서 아래 4가지를 <b>7점 리커트 척도</b>로 측정하였다.</p>
                    <p class="font-sans-serif-kr">
                        측정을 통해, 사용자가 각 로봇의 표현 방식에 따라 사용자에게 위치 정보를 얼마나 효과적으로, 사회적으로, 자연스럽게 제공하는지 확인하였다.<br>
                        또한, 로봇에 대한 전반적인 인상을 알아보기위해 제품 평가를 조사하였다.
                    </p>
                    <ul>
                        <li class="font-sans-serif-kr">효율성(perceived effectiveness)<sup id="R05"><a href="#refer05">5</a></sup></li>
                        <li class="font-sans-serif-kr">사교성(perceived sociability)<sup id="R06"><a href="#refer06">6</a></sup></li>
                        <li class="font-sans-serif-kr">자연스러움(perceived naturalness)<sup id="R05"><a href="#refer05">5</a></sup></li>
                        <li class="font-sans-serif-kr">제품 평가(product evaluation)<sup id="R07"><a href="#refer07">7,</a></sup><sup id="R08"><a href="#refer08"> 8</a></sup></li>
                    </ul>
                    <p class="font-sans-serif-kr">진행되었던 실험 중, 전시 안내 상황에서는 로봇의 설명에 대한 인식을 알아보기 위해 아래 2가지를 추가적으로 측정하였다.</p>
                    <ul>
                        <li class="font-sans-serif-kr">유능함(perceived competency)<sup id="R06"><a href="#refer06">6</a></sup></li>
                        <li class="font-sans-serif-kr">신뢰성(perceived trustworthiness)<sup id="R06"><a href="#refer06">6</a></sup></li>
                    </ul>
                    <details>
                        <summary class="font-sans-serif-kr" style="cursor:pointer">질문 아이템</summary>
                        <div class="img-wrapper" data-aos="fade-up">
                            <img src="../assets/image/this-or-that/study-design-03.png">
                            <img src="../assets/image/this-or-that/study-design-04.png">
                            <p class="font-sans-serif-kr">4가지 공통 측정과 2가지 추가 측정에 대한 아이템</p>
                        </div>
                    </details>
                </div>
                <div class="project-detail">
                    <h2 class="font-sans-serif-en">Seat Guide</h2>
                    <p class="font-sans-serif-kr">
						로봇은 피험자를 맞이하고 자리를 안내한다.
						피험자는 연구실에 배치된 5개의 의자 중 로봇이 포인팅 하는 의자에 앉도록 요청받았다.
					</p>
                    <div class="img-wrapper" data-aos="fade-up">
                        <img src="../assets/image/this-or-that/seat-guide-01.png">
                        <img src="../assets/image/this-or-that/seat-guide-02.png">
                        <p class="font-sans-serif-kr">자리 안내 실험 환경</p>
                    </div>
                    <h3 class="font-sans-serif-en">Procedure</h3>
                    <p class="font-sans-serif-kr">
                        피험자는 무작위 순서로 총 4번의 착석 요청을 받았으며, 각 착석 이후에 로봇의 인상을 평가했다.
                        로봇의 언어 및 제스처 표현 예는 다음과 같다.
                    </p>
                    <div class="img-wrapper" data-aos="fade-up">
                        <img src="../assets/image/this-or-that/seat-guide-03.png">
                    </div>
                    <h3 class="font-sans-serif-en">Results</h3>
					<p class="font-sans-serif-kr">실험을 통해 각 조건의 로봇이 사용자의 인식에 미치는 영향을 조사하기 위해 <b>이원 반복측정 분산분석(two-way RM ANOVA)</b>을 수행했다.</p>
                    <h4 class="font-sans-serif-kr">사용한 소프트웨어</h4>
                    <li class="font-sans-serif-kr">데이터 분석: SPSS</li>
                    <p class="font-sans-serif-kr">로봇의 효율성, 사교성, 자연스러움 및 제품 평가 측정에 대해 신뢰도 분석(Cronbach's alpha) 시, 모두 0.6 이상으로 유의한 결과가 나왔다.</p>
                    <details>
                        <summary class="font-sans-serif-kr" style="cursor:pointer">신뢰도 분석 결과</summary>
                        <div class="img-wrapper" data-aos="fade-up">
                            <img src="../assets/image/this-or-that/seat-guide-04.png">
                            <p class="font-sans-serif-kr">각 측정에 대한 신뢰도 분석 후 Cronbach's alpha 계수</p>
                        </div>
                    </details>
                    <div class="img-wrapper" data-aos="fade-up">
                        <h4 class="font-sans-serif-kr">주 효과</h4>
                        <img src="../assets/image/this-or-that/seat-guide-05.png">
                        <img src="../assets/image/this-or-that/seat-guide-06.png">
                    </div>
                </div>
                <div class="project-detail">
                    <h2 class="font-sans-serif-en">Exhibition Guide</h2>
                    <p class="font-sans-serif-kr">
                        피험자는 안내 로봇을 통해 로봇 쇼룸에 전시된 로봇에 대한 설명을 듣는다.<br>
                        안내 로봇은 전시된 5개의 로봇을 하나씩 포인팅 하면서 설명하고, 피험자는 메모지에 안내 로봇이 포인팅 한 순서대로 메모한다.
                    </p>
                    <div class="img-wrapper" data-aos="fade-up">
                        <img src="../assets/image/this-or-that/exhibition-guide-01.png">
                        <img src="../assets/image/this-or-that/exhibition-guide-02.png">
                        <p class="font-sans-serif-kr">전시 안내 실험 환경</p>
                    </div>
                    <h3 class="font-sans-serif-en">Procedure</h3>
					<p class="font-sans-serif-kr">피험자는 무작위 순서로 총 4번의 조건을 경험했으며, 각 조건 이후에 로봇의 인상을 평가했다. 로봇의 언어 및 제스처 표현 예는 다음과 같다.</p>
                    <div class="img-wrapper" data-aos="fade-up">
                        <img src="../assets/image/this-or-that/exhibition-guide-03.png">
                    </div>
                    <h3 class="font-sans-serif-en">Results</h3>
					<p class="font-sans-serif-kr">실험을 통해 각 조건의 로봇이 사용자의 인식에 미치는 영향을 조사하기 위해 <b>이원 반복측정 분산분석(two-way RM ANOVA)</b>을 수행했다.</p>
                    <h4 class="font-sans-serif-kr">사용한 소프트웨어</h4>
                    <li class="font-sans-serif-kr">데이터 분석: SPSS</li>
                    <p class="font-sans-serif-kr">로봇의 효율성, 사교성, 자연스러움, 유능함, 신뢰성 및 제품 평가 측정에 대해 신뢰도 분석(Cronbach's alpha) 시, 모두 0.6 이상으로 유의한 결과가 나왔다.</p>
                    <details>
                        <summary style="cursor:pointer">신뢰도 분석 결과</summary>
                        <div class="img-wrapper" data-aos="fade-up">
                            <img src="../assets/image/this-or-that/exhibition-guide-04.png">
                            <p class="font-sans-serif-kr">각 측정에 대한 신뢰도 분석 후 Cronbach's alpha 계수</p>
                        </div>
                    </details>
                    <div class="img-wrapper" data-aos="fade-up">
                        <h4 class="font-sans-serif-kr">주 효과</h4>
                        <img src="../assets/image/this-or-that/exhibition-guide-05.png">
                        <img src="../assets/image/this-or-that/exhibition-guide-06.png">
                        <h4 class="font-sans-serif-kr">상호작용 효과</h4>
                        <img src="../assets/image/this-or-that/exhibition-guide-07.png">
                    </div>
                </div>
                <div class="project-detail">
                    <h2 class="font-sans-serif-en">Conclusion</h2>
                    <h3 class="font-sans-serif-en">Interpretation of Results</h3>
    				<p class="font-sans-serif-kr">결과에 대한 해석은 다음과 같다.</p>
                    <ul>
                        <li class="font-sans-serif-kr">사람들은 명령문과 평서문 포인팅 상황에 상관없이 서술적 언어 유형과 코 포인팅을 사용하여 위치 정보를 제공하는 것을 전반적으로 선호하였다.</li>
                        <li class="font-sans-serif-kr">위치 정보 인식의 정확성은 언어 유형이 중요하다. 자리 안내 상황에서는 피실험자와 로봇이 마주보고 있었기 때문에 왼쪽과 오른쪽을 반대로 생각하는 사람들이 존재했다.</li>
                    </ul>
                    <h3 class="font-sans-serif-en">Implication</h3>
    				<p class="font-sans-serif-kr">본 연구는 다음과 같은 영향을 줄 수 있다.</p>
                    <ul>
                        <li class="font-sans-serif-kr">인간의 사회적 상호작용 연구에 기여할 수 있다. 인간 연구에서는 코를 탈부착할 수 없지만, 인공물인 로봇에서는 코의 영향에 관한 연구가 가능하다.</li>
                        <li class="font-sans-serif-kr">로봇의 발화 스타일 디자인 연구에 기여할 수 있다. 서술적 언어 유형에서는 사용자와 기준점을 일치시켜야 하며, 마주봐야 하는 경우에는 지시적 언어 유형으로 제공되어야 한다.</li>
						<li class="font-sans-serif-kr">로봇의 디자인 개선에 기여할 수 있다. 로봇이 제공한 정보가 사용자에게 치명적인 영향을 미치지 않는 경우, 사용자가 더 선호하는 서술적 언어 유형으로 제공하도록 디자인되어야 한다.</li>
                    </ul>
                    <div class="img-wrapper" data-aos="fade-up">
                        <img src="../assets/image/this-or-that/conclusion-01.png">
                        <p class="font-sans-serif-kr">사용자와 로봇이 기준점이 같은 경우와 다른 경우</p>
                    </div>
                    <h3 class="font-sans-serif-en">Limitation & Future Work</h3>
    				<p class="font-sans-serif-kr">본 연구의 한계점은 다음과 같다.</p>
                    <ul>
                        <li class="font-sans-serif-kr">본 연구는 단일 환경을 설정했지만, 사용자와 로봇 사이의 거리를 고려하여 보다 다양하고 자연스러운 실험 환경에서 연구를 수행할 수 있다.</li>
                        <li class="font-sans-serif-kr">본 연구는 위치 정보 인식의 정확성을 측정했지만, 사용자가 위치를 인식하는데 걸린 시간을 측정해서 각 조건의 유효성을 알아볼 수 있다.</li>
                    </ul>
                </div>
                <div class="project-detail">
                    <h2 class="font-sans-serif-en">Publication</h2>
                    <p class="font-sans-serif-en"><a class="black-link" href="https://ieeexplore.ieee.org/document/9341067"><b>This or That: The Effect of Robot’s Deictic Expression on User’s Perception</b><br><font size="2em">2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</font></a></p>
                </div>
                <div class="project-detail">
                    <h3 class="font-sans-serif-en">References</h3>
                    <p class="font-sans-serif-en" style="font-size:0.7em"><a name="refer01">[1] <a class="black-link" href="https://books.google.co.kr/books?id=JlN4AgAAQBAJ&lpg=PP1&ots=pP-gJzkuK8&dq=Pointing%3A%20Where%20Language%2C%20Culture%2C%20and%20Cognition%20Meet&lr&hl=ko&pg=PP1#v=onepage&q=Pointing:%20Where%20Language,%20Culture,%20and%20Cognition%20Meet&f=false"><b>Pointing: Where Language, Culture, and Cognition Meet</b></a> (2003) by Sotaro Kita <a href="#R01" style="text-decoration:none; color:#407CF7;"><b>↩</b></a></p>
                    <p class="font-sans-serif-en" style="font-size:0.7em"><a name="refer02">[2] <a class="black-link" href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=51D1CBC4966CC0EDAAF34593B83E30F3?doi=10.1.1.462.5492&rep=rep1&type=pdf"><b>The Role of Gesture in Communication and Thinking</b></a> (1999) by Susan Goldin-Meadow in Trends in Cognitive Sciences <a href="#R02" style="text-decoration:none; color:#407CF7;"><b>↩</b></a></p>
                    <p class="font-sans-serif-en" style="font-size:0.7em"><a name="refer03">[3] <a class="black-link" href="https://ieeexplore.ieee.org/document/6247845"><b>We Are Not Contortionists: Coupled Adaptive Learning for Head and Body Orientation Estimation in Surveillance Video</b></a> (2012) by Cheng Chen and Jean-Marc Odobez in IEEE Conference on Computer Vision and Pattern Recognition <a href="#R03" style="text-decoration:none; color:#407CF7;"><b>↩</b></a></p>
                    <p class="font-sans-serif-en" style="font-size:0.7em"><a name="refer04">[4] <a class="black-link" href="https://books.google.co.kr/books?id=jK5nk7iDgSYC&lpg=PT1&dq=Becoming%20Human%3A%20From%20Pointing%20Gestures%20to%20Syntax&lr&hl=ko&pg=PT1#v=onepage&q=Becoming%20Human:%20From%20Pointing%20Gestures%20to%20Syntax&f=false"><b>Becoming Human: From Pointing Gestures to Syntax</b></a> (2011) by Teresa Bejarano <a href="#R04" style="text-decoration:none; color:#407CF7;"><b>↩</b></a></p>
                    <p class="font-sans-serif-en" style="font-size:0.7em"><a name="refer05">[5] <a class="black-link" href="https://ieeexplore.ieee.org/abstract/document/8542607"><b>Robot Deictics: How Gesture and Context Shape Referential Communication</b></a> (2014) by Allison Sauppé and Bilge Mutlu in ACM/IEEE HRI <a href="#R05" style="text-decoration:none; color:#407CF7;"><b>↩</b></a></p>
                    <p class="font-sans-serif-en" style="font-size:0.7em"><a name="refer06">[6] <a class="black-link" href="https://ieeexplore.ieee.org/abstract/document/6483608"><b>Rhetorical Robots: Making Robots More Effective Speakers Using Linguistic Cues of Expertise</b></a> (2013) by Sean Andrist, Erin Spannan and Bilge Mutlu in ACM/IEEE HRI <a href="#R06" style="text-decoration:none; color:#407CF7;"><b>↩</b></a></p>
                    <p class="font-sans-serif-en" style="font-size:0.7em"><a name="refer07">[7] <a class="black-link" href="https://journals.sagepub.com/doi/10.1509/jmkr.44.2.251"><b>Adoption of New and Really New Products: The Effects of Self-Regulation Systems and Risk Salience</b></a> (2007) by Michal Herzenstein, Steven S. Posavac and J. Joško Brakus in Journal of Marketing Research <a href="#R07" style="text-decoration:none; color:#407CF7;"><b>↩</b></a></p>
                    <p class="font-sans-serif-en" style="font-size:0.7em"><a name="refer08">[8] <a class="black-link" href="https://journals.sagepub.com/doi/10.1509/jmkr.46.1.46"><b>The Role of Imagination-Focused Visualization on New Product Evaluation</b></a> (1989) by Min Zhao, Steve Hoeffler and Darren W. Dahl in Journal of Marketing Research <a href="#R08" style="text-decoration:none; color:#407CF7;"><b>↩</b></a></p>
                  </div>
            </div>
        </section>

        <div class="top-container">
            <a onclick="toTop()"><img id="button-top" src="../assets/image/footer-icon/totop.png" alt="totop"></a>
        </div>
        <script>
            function toTop() {
                window.scrollTo({top:0, left:0, behavior:'smooth'});
            }
        </script>
    </main>

    <footer>
        <div class="footer-bar">
            <div class="footer-content">
              <h1 class="copyright font-sans-serif-en">© 2022 Hanbyeol Lee</h1>
              <div class="sns-wrapper">
                <a href="https://www.linkedin.com/in/hanbyeol-lee-2a3a01108/"><img src="../assets/image/footer-icon/linkedin.png" alt="linkedin"></a>
                <a href="https://github.com/hanby-uxengineer"><img src="../assets/image/footer-icon/github.png" alt="github"></a>
                <a href="https://scholar.google.com/citations?user=J2aMC2gAAAAJ&hl=ko"><img src="../assets/image/footer-icon/scholar.png" alt="scholar"></a>
                <a href="mailto:yihaanstar@gmail.com?subject=안녕하세요!"><img src="../assets/image/footer-icon/email.png" alt="email"></a>
              </div>
            </div>
          </div>
    </footer>
    
</body>
</html>